{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'embeddings', 'test.csv', 'train.csv.zip', 'sample_submission.csv', 'embeddings.zip', 'test.csv.zip', 'sample_submission.csv.zip']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "DATA_PATH = \"../input\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (1306122, 3)\n",
      "Test shape :  (56370, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(DATA_PATH, \"train.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(DATA_PATH, \"test.csv\"))\n",
    "print(\"Train shape : \", train_df.shape)\n",
    "print(\"Test shape : \", test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "ab2ed2b08c8d3292316ce35ca6f801198aa3cb49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22                                                                                                      Has the United States become the largest dictatorship in the world?\n",
      "30                                                                                   Which babies are more sweeter to their parents? Dark skin babies or light skin babies?\n",
      "110                                                                  If blacks support school choice and mandatory sentencing for criminals why don't they vote Republican?\n",
      "114                               I am gay boy and I love my cousin (boy). He is sexy, but I dont know what to do. He is hot, and I want to see his di**. What should I do?\n",
      "115                                                                                                                                    Which races have the smallest penis?\n",
      "119                                                                                                                                       Why do females find penises ugly?\n",
      "127                                                                                             How do I marry an American woman for a Green Card? How much do they charge?\n",
      "144                   Why do Europeans say they're the superior race, when in fact it took them over 2,000 years until mid 19th century to surpass China's largest economy?\n",
      "156                                                                     Did Julius Caesar bring a tyrannosaurus rex on his campaigns to frighten the Celts into submission?\n",
      "167    In what manner has Republican backing of 'states rights' been hypocritical and what ways have they actually restricted the ability of states to make their own laws?\n",
      "Name: question_text, dtype: object\n",
      "0                                                                                                                                   How did Quebec nationalists see their province as a nation in the 1960s?\n",
      "1                                                                                                                          Do you have an adopted dog, how would you encourage people to adopt and not shop?\n",
      "2                                                                                                                                        Why does velocity affect time? Does velocity affect space geometry?\n",
      "3                                                                                                                                                  How did Otto von Guericke used the Magdeburg hemispheres?\n",
      "4                                                                                                                              Can I convert montra helicon D to a mountain bike by just changing the tyres?\n",
      "5                                                                                                                                   Is Gaza slowly becoming Auschwitz, Dachau or Treblinka for Palestinians?\n",
      "6                                                                                          Why does Quora automatically ban conservative opinions when reported, but does not do the same for liberal views?\n",
      "7                                                                                                                                      Is it crazy if I wash or wipe my groceries off? Germs are everywhere.\n",
      "8                                                                                                     Is there such a thing as dressing moderately, and if so, how is that different than dressing modestly?\n",
      "9    Is it just me or have you ever been in this phase wherein you became ignorant to the people you once loved, completely disregarding their feelings/lives so you get to have something go your way an...\n",
      "Name: question_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "insincere_df = train_df.loc[train_df[\"target\"] == 1]\n",
    "sincere_df = train_df.loc[train_df[\"target\"] == 0]\n",
    "pd.set_option(\"max_colwidth\",200)\n",
    "print(insincere_df.head(10)[\"question_text\"])\n",
    "print(sincere_df.head(10)[\"question_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "4fcba32677ec2800fc2498c4679f9fc61490398b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    qid  \\\n",
      "0  00002165364db923c7e6   \n",
      "1  000032939017120e6e44   \n",
      "2  0000412ca6e4628ce2cf   \n",
      "3  000042bf85aa498cd78e   \n",
      "4  0000455dfa3e01eae3af   \n",
      "\n",
      "                                                                       question_text  \\\n",
      "0           How did Quebec nationalists see their province as a nation in the 1960s?   \n",
      "1  Do you have an adopted dog, how would you encourage people to adopt and not shop?   \n",
      "2                Why does velocity affect time? Does velocity affect space geometry?   \n",
      "3                          How did Otto von Guericke used the Magdeburg hemispheres?   \n",
      "4      Can I convert montra helicon D to a mountain bike by just changing the tyres?   \n",
      "\n",
      "   target  sentence_len  \n",
      "0       0            13  \n",
      "1       0            16  \n",
      "2       0            10  \n",
      "3       0             9  \n",
      "4       0            15  \n",
      "134\n",
      "4\n",
      "                         qid  \\\n",
      "24672   04d636e33c281a54bfac   \n",
      "165040  2041ae71c5a8c0cba026   \n",
      "253514  319da4906df672a86606   \n",
      "522266  663c7523d48f5ee66a3e   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                          question_text  \\\n",
      "24672                                                                                                                                                                    Let A be a set of all integers between 0 to 100 Let B be a set of all odd numbers Let C be a set of all composite numbers May I define a set D that is the intersection of B and C within the scope of A as D = {d : d ∈ B ∩ C, B ⊆ A, C ⊆ A}?   \n",
      "165040                                                                     To you, does being a Christian mean  inviting in the spirit of Jesus into you and suppressing our own spirit? 'Thy will not mine' and all that? Do you like living as a zombie of someone else's spirit - however perfect it may be? Don't you want to experience and improve your own will and spirit and live your life as you, not Jesus?   \n",
      "253514                                                                                                                                                                                  What is the value of k in $\\begin {array} kx & + & y & + & z & = & 1 \\\\ x & + & ky & + & z & = & 1 \\\\ x & + & y & + & kz & = & 1 \\end {array} $ such that the sistem has a single solution, infinite solutions and no solution?   \n",
      "522266  In \"Star Trek 2013\" why did they :\\n\\n*Spoilers*\\n*Spoilers*\\n*Spoilers*\\n*Spoilers*\\n\\n1)Make warping look quite a bit like an hyperspace jump\\n2)what in the world were those bright particles as soon as they jumped.\\n3)Why in the world did they make it possible for two entities to react in warp space in separate jumps.\\n4)Why did Spock get emotions for this movie.\\n5)What was the point of hid...   \n",
      "\n",
      "        target  sentence_len  \n",
      "24672        0            65  \n",
      "165040       1            64  \n",
      "253514       0            66  \n",
      "522266       0           134  \n"
     ]
    }
   ],
   "source": [
    "# #显示所有列\n",
    "# pd.set_option('display.max_columns', None)\n",
    "# #显示所有行\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# #设置value的显示长度为100，默认为50\n",
    "# pd.set_option('max_colwidth', 400)\n",
    "\n",
    "# # print the longest sentence\n",
    "# sentence_len = train_df[\"question_text\"].apply(lambda x: len(str(x).split()))\n",
    "# # add a col\n",
    "# train_df[\"sentence_len\"] = sentence_len\n",
    "# print(train_df.head(5))\n",
    "# longest_len = np.max(sentence_len)\n",
    "# print(longest_len)\n",
    "# longest_sentence = train_df.loc[train_df[\"sentence_len\"] >= longest_len-70]\n",
    "# # pd.set_option(\"max_colwidth\", 10*int(longest_len))\n",
    "# print(len(longest_sentence))\n",
    "# print(longest_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "200b43d07d209c6d58b7bc01a5621cce3d63c33c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24672                                                                                                                                                                                                                                                                                     let set integers 0 let b set odd numbers let c set composite numbers define set d intersection b c scope d d d ∈ b ∩ c b ⊆ c ⊆ \n",
      "165040                                                                                                                                                                                                                                                              christian mean inviting spirit jesus suppressing spirit thy like living zombie s spirit perfect don t want experience improve spirit live life jesus \n",
      "253514                                                                                                                                                                                                                                                                                                       value k begin array kx y z 1 x ky z 1 x y kz 1 end array sistem single solution infinite solutions solution \n",
      "522266    star trek spoilers spoilers spoilers spoilers 1 warping look bit like hyperspace jump 2 world bright particles soon jumped 3 world possible entities react warp space separate jumps 4 spock emotions movie 5 point hiding enterprise underwater 6 intercepted dark ship come reached earth far away don t remember scene warp earth 7 ship enter earth s atmosphere wasnt orbit 8 scotty opened door black ...\n",
      "Name: question_text, dtype: object\n",
      "24672     32\n",
      "165040    23\n",
      "253514    24\n",
      "522266    72\n",
      "Name: question_text, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mr-zhou/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:127: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# clean data\n",
    "def clean_data(sentence):\n",
    "    # 1. lower\n",
    "    x = str(sentence)\n",
    "    x = x.lower()\n",
    "    \n",
    "    # 2. punct data\n",
    "    puncts = [\n",
    "        ',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    "        '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    "        '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    "        '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    "        '∙', '）', '↓', '、', '│', '₹', 'π', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\n",
    "    for punct in puncts:\n",
    "        if punct in x:\n",
    "            x = x.replace(punct, ' ')\n",
    "    for punct in '&':\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    \n",
    "    # 3. number data\n",
    "    x = re.sub('[0-9]{5,}', ' ##### ', x)\n",
    "    x = re.sub('[0-9]{4}', ' #### ', x)\n",
    "    x = re.sub('[0-9]{3}', ' ### ', x)\n",
    "    x = re.sub('[0-9]{2}', ' ## ', x)\n",
    "    \n",
    "    # 4. mispell data\n",
    "    mispell_dict = {\n",
    "        \"aren't\" : \"are not\",\n",
    "        \"can't\" : \"cannot\",\n",
    "        \"couldn't\" : \"could not\",\n",
    "        \"didn't\" : \"did not\",\n",
    "        \"doesn't\" : \"does not\",\n",
    "        \"don't\" : \"do not\",\n",
    "        \"hadn't\" : \"had not\",\n",
    "        \"hasn't\" : \"has not\",\n",
    "        \"haven't\" : \"have not\",\n",
    "        \"he'd\" : \"he would\",\n",
    "        \"he'll\" : \"he will\",\n",
    "        \"he's\" : \"he is\",\n",
    "        \"i'd\" : \"I would\",\n",
    "        \"i'd\" : \"I had\",\n",
    "        \"i'll\" : \"I will\",\n",
    "        \"i'm\" : \"I am\",\n",
    "        \"isn't\" : \"is not\",\n",
    "        \"it's\" : \"it is\",\n",
    "        \"it'll\":\"it will\",\n",
    "        \"i've\" : \"I have\",\n",
    "        \"let's\" : \"let us\",\n",
    "        \"mightn't\" : \"might not\",\n",
    "        \"mustn't\" : \"must not\",\n",
    "        \"shan't\" : \"shall not\",\n",
    "        \"she'd\" : \"she would\",\n",
    "        \"she'll\" : \"she will\",\n",
    "        \"she's\" : \"she is\",\n",
    "        \"shouldn't\" : \"should not\",\n",
    "        \"that's\" : \"that is\",\n",
    "        \"there's\" : \"there is\",\n",
    "        \"they'd\" : \"they would\",\n",
    "        \"they'll\" : \"they will\",\n",
    "        \"they're\" : \"they are\",\n",
    "        \"they've\" : \"they have\",\n",
    "        \"we'd\" : \"we would\",\n",
    "        \"we're\" : \"we are\",\n",
    "        \"weren't\" : \"were not\",\n",
    "        \"we've\" : \"we have\",\n",
    "        \"what'll\" : \"what will\",\n",
    "        \"what're\" : \"what are\",\n",
    "        \"what's\" : \"what is\",\n",
    "        \"what've\" : \"what have\",\n",
    "        \"where's\" : \"where is\",\n",
    "        \"who'd\" : \"who would\",\n",
    "        \"who'll\" : \"who will\",\n",
    "        \"who're\" : \"who are\",\n",
    "        \"who's\" : \"who is\",\n",
    "        \"who've\" : \"who have\",\n",
    "        \"won't\" : \"will not\",\n",
    "        \"wouldn't\" : \"would not\",\n",
    "        \"you'd\" : \"you would\",\n",
    "        \"you'll\" : \"you will\",\n",
    "        \"you're\" : \"you are\",\n",
    "        \"you've\" : \"you have\",\n",
    "        \"'re\": \" are\",\n",
    "        \"wasn't\": \"was not\",\n",
    "        \"we'll\":\" will\",\n",
    "        \"didn't\": \"did not\",\n",
    "        \"tryin'\":\"trying\",\n",
    "\n",
    "        'colour':'color',\n",
    "        'centre':'center',\n",
    "        'didnt':'did not',\n",
    "        'doesnt':'does not',\n",
    "        'isnt':'is not',\n",
    "        'shouldnt':'should not',\n",
    "        'favourite':'favorite',\n",
    "        'travelling':'traveling',\n",
    "        'counselling':'counseling',\n",
    "        'theatre':'theater',\n",
    "        'cancelled':'canceled',\n",
    "        'labour':'labor',\n",
    "        'organisation':'organization',\n",
    "        'wwii':'world war 2',\n",
    "        'citicise':'criticize',\n",
    "        'instagram': 'social medium',\n",
    "        'whatsapp': 'social medium',\n",
    "        'snapchat': 'social medium'\n",
    "    }\n",
    "    mispell_re = re.compile('(%s)' % '|'.join(mispell_dict.keys()))\n",
    "    def replace(match):\n",
    "        return mispell_dict[match.group(0)]\n",
    "    x = mispell_re.sub(replace, x)\n",
    "    \n",
    "    \n",
    "    # 5. stop words\n",
    "    tmp = \"\"\n",
    "    for word in x.split():\n",
    "        if word not in list(STOP_WORDS):\n",
    "            tmp = tmp + word + \" \"\n",
    "    x = tmp\n",
    "    \n",
    "    return x\n",
    "\n",
    "# longest_sentence[\"question_text\"] = longest_sentence[\"question_text\"].apply(lambda x: clean_data(x))\n",
    "# print(longest_sentence[\"question_text\"])\n",
    "# sentence_len = longest_sentence[\"question_text\"].apply(lambda x: len(str(x).split()))\n",
    "# print(sentence_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "f331437af6769d9eb35c34c74e7741dbf4e4fa60"
   },
   "outputs": [],
   "source": [
    "# Loading embedding\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "GLOVE_PATH = os.path.join(DATA_PATH, \"embeddings\", \"glove.840B.300d\", \"glove.840B.300d.txt\")\n",
    "glove_mean = -0.005838499\n",
    "glove_std = 0.48782197\n",
    "GOOGLENEWS_PATH = os.path.join(DATA_PATH, \"embeddings\", \"GoogleNews-vectors-negative300\", \"GoogleNews-vectors-negative300.bin\")\n",
    "PARAGRAM_PATH =  os.path.join(DATA_PATH, \"embeddings\", \"paragram_300_sl999\", \"paragram_300_sl999.txt\")\n",
    "paragram_mean = -0.0053247944\n",
    "paragram_std = 0.49346468\n",
    "WIKI_NEWS = os.path.join(DATA_PATH, \"embeddings\", \"wiki-news-300d-1M\", \"wiki-news-300d-1M.vec\")\n",
    "\n",
    "def load_embedding(file):\n",
    "    def get_coefs(word, *arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    if file == GOOGLENEWS_PATH:\n",
    "        embeddings_index = KeyedVectors.load_word2vec_format(file, binary=True)\n",
    "    elif file == os.path.join(DATA_PATH, \"embeddings\", \"wiki-news-300d-1M\", \"wiki-news-300d-1M.vec\"):\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o)>100)\n",
    "    else:\n",
    "        embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n",
    "        \n",
    "    return embeddings_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "_uuid": "ccbce3ef1ba4c0d284648d7d96cf40928f117e26"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "vocab_size = 120000\n",
    "\n",
    "def build_vocab(sentences, verbose=True):\n",
    "    # Tokenize the sentences\n",
    "    tokenizer = Tokenizer(\n",
    "        num_words=vocab_size,\n",
    "        filters = '!\"#$%()*+,-./:;<=>?@[\\]^_`{|}~ '\n",
    "    )\n",
    "    tokenizer.fit_on_texts(sentences)\n",
    "    vocab = tokenizer.word_counts\n",
    "    print(\"word_index_len : \", len(vocab))\n",
    "#     \"\"\"\n",
    "#     :param sentences: list of list of words\n",
    "#     :return: dictionary of words and their count\n",
    "#     \"\"\"\n",
    "#     vocab = {}\n",
    "#     for sentence in tqdm(sentences, disable = (not verbose)):\n",
    "#         for word in sentence.split():\n",
    "#             try:\n",
    "#                 vocab[word] += 1\n",
    "#             except KeyError:\n",
    "#                 vocab[word] = 1\n",
    "#     print(\"word_index_len : \", len(vocab))\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "e3062116f958e829bf71f5a457f9fa3899d8433d"
   },
   "outputs": [],
   "source": [
    "import operator \n",
    "\n",
    "def check_coverage(vocab,embeddings_index):\n",
    "    a = {}\n",
    "    oov = {}\n",
    "    k = 0\n",
    "    i = 0\n",
    "    for word in tqdm(vocab):\n",
    "        try:\n",
    "            a[word] = embeddings_index[word]\n",
    "            k += vocab[word]\n",
    "        except:\n",
    "\n",
    "            oov[word] = vocab[word]\n",
    "            i += vocab[word]\n",
    "            pass\n",
    "\n",
    "    print('Found embeddings for {:.2%} of vocab'.format(len(a) / len(vocab)))\n",
    "    print('Found embeddings for  {:.2%} of all text'.format(k / (k + i)))\n",
    "    sorted_x = sorted(oov.items(), key=operator.itemgetter(1))[::-1]\n",
    "\n",
    "    return sorted_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "2767e44152f651b24948b0ccd242fc0d6559d836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin load embedding ...\n",
      "Loading embedding completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin load embedding ...\")\n",
    "embeddings_index = load_embedding(GLOVE_PATH)\n",
    "print(\"Loading embedding completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "_uuid": "5b063be035b428c03d26157f53cd05cf1484e9bf",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1306122/1306122 [01:31<00:00, 14343.23it/s]\n",
      "100%|██████████| 185187/185187 [00:00<00:00, 1301581.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word_index_len :  185187\n",
      "Found embeddings for 63.40% of vocab\n",
      "Found embeddings for  98.56% of all text\n",
      "[('quorans', 858), ('brexit', 524), ('cryptocurrencies', 499), ('redmi', 384), ('kvpy', 356), ('paytm', 356), ('iiser', 346), ('ethereum', 334), ('iisc', 278), ('jinping', 211), ('viteee', 186), ('iocl', 179), ('nmims', 163), ('upes', 157), ('rohingya', 157), ('fortnite', 156), ('coinbase', 149), ('nsit', 147), ('cpec', 146), ('iitians', 143)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Begin clean data ...\")\n",
    "clean_sentences = train_df[\"question_text\"].progress_apply(\n",
    "    lambda x: clean_data(x))\n",
    "print(\"Clean data completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Begin build_vocab ...\")\n",
    "clean_vocab = build_vocab(clean_sentences)\n",
    "print(\"Build vocab completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('quorans', 858), ('brexit', 524), ('cryptocurrencies', 499), ('redmi', 384), ('kvpy', 356), ('paytm', 356), ('iiser', 346), ('ethereum', 334), ('iisc', 278), ('jinping', 211), ('viteee', 186), ('iocl', 179), ('nmims', 163), ('upes', 157), ('rohingya', 157), ('fortnite', 156), ('coinbase', 149), ('nsit', 147), ('cpec', 146), ('iitians', 143), ('oneplus', 139), ('jadavpur', 138), ('udemy', 128), ('lyft', 126), ('uceed', 124), ('afcat', 123), ('bahubali', 123), ('coep', 119), ('demonetisation', 115), ('bhakts', 115), ('upwork', 111), ('machedo', 108), ('nlu', 107), ('gdpr', 107), ('adityanath', 106), ('upsee', 105), ('boruto', 102), ('bnbr', 100), ('chsl', 99), ('kernan', 97), ('josaa', 94), ('amcat', 94), ('kylo', 93), ('udacity', 93), ('vishwanathan', 92), ('alshamsi', 92), ('iitian', 91), ('dceu', 90), ('litecoin', 87), ('iiest', 86), ('unacademy', 86), ('rvce', 84), ('sjws', 84), ('laravel', 84), ('qoura', 82), ('vjti', 81), ('zerodha', 80), ('corbyn', 77), ('msrit', 76), ('xlri', 76), ('iitb', 75), ('tensorflow', 74), ('intps', 73), ('jiit', 72), ('ctmu', 72), ('gitam', 71), ('hyperloop', 70), ('doklam', 70), ('kavalireddi', 69), ('lnmiit', 68), ('intjs', 67), ('myntra', 67), ('muoet', 66), ('xamarin', 65), ('mnnit', 65), ('nitk', 64), ('tywin', 63), ('shibpur', 62), ('nicmar', 62), ('kotlin', 62), ('banasthali', 61), ('moocs', 61), ('ggsipu', 61), ('niser', 61), ('nptel', 61), ('vajiram', 60), ('modiji', 60), ('manafort', 59), ('adhaar', 59), ('srmjee', 58), ('zebpay', 58), ('duterte', 58), ('infjs', 57), ('elitmus', 57), ('hackerrank', 54), ('altcoin', 54), ('altcoins', 54), ('pubg', 54), ('biharis', 54), ('aurangzeb', 54), ('draupadi', 52), ('wakanda', 52), ('jiren', 52), ('awdhesh', 52), ('crispr', 51), ('aiq', 51), ('sibm', 51), ('nitie', 51), ('vnit', 51), ('hamirpur', 50), ('ryzen', 50), ('pichai', 50), ('mamc', 50), ('rohingyas', 49), ('duolingo', 49), ('koinex', 48), ('pcmb', 48), ('baahubali', 48), ('hpcl', 48), ('tifr', 47), ('srcc', 46), ('mhcet', 45), ('binance', 45), ('tennesseans', 45), ('byju', 44), ('nabard', 44), ('tillerson', 43), ('snoke', 43), ('mnit', 42), ('zomato', 42), ('srmjeee', 42), ('veaux', 42), ('beerus', 41), ('ftre', 40), ('ximb', 40), ('skripal', 40), ('sgsits', 40), ('kulbhushan', 39), ('mindtree', 39), ('littlefinger', 39), ('sadhguru', 38), ('θ', 38), ('mhtcet', 38), ('hotstar', 38), ('gurugram', 38), ('nanodegree', 38), ('what\\u200b', 37), ('pdpu', 37), ('npat', 37), ('ramanujan', 37), ('sindri', 37), ('bmsce', 37), ('ravula', 36), ('iima', 36), ('ramapuram', 36), ('kalanick', 36), ('kaggle', 36), ('microservices', 36), ('dangal', 36), ('rhaegar', 36), ('jiofi', 36), ('bipc', 36), ('jbims', 35), ('kathua', 35), ('sarahah', 34), ('gionee', 34), ('usict', 34), ('rera', 34), ('truecaller', 34), ('ramaiah', 34), ('swachh', 34), ('obor', 34), ('cbit', 34), ('surathkal', 34), ('azerbaijanis', 34), ('lyanna', 33), ('lbsnaa', 33), ('patreon', 33), ('bhms', 33), ('afsb', 33), ('zenfone', 33), ('clickbait', 33), ('pesit', 32), ('gofundme', 32), ('daiict', 32), ('quara', 32), ('reactjs', 32), ('dushka', 32), ('altucher', 32), ('manit', 32), ('bittrex', 31), ('chromecast', 31), ('cdse', 31), ('nchmct', 31), ('bpcl', 31), ('pcod', 30), ('pessat', 30), ('yiannopoulos', 30), ('infps', 30), ('sjce', 30), ('kasol', 30), ('andme', 30), ('rlwl', 30), ('bosniaks', 30), ('codechef', 30), ('iitk', 30), ('bs4', 29), ('jungkook', 29), ('ahmadabad', 29), ('bhubaneshwar', 29), ('gujaratis', 29), ('iisers', 29), ('demonitisation', 29), ('msit', 29), ('nimhans', 29), ('galgotia', 28), ('monero', 28), ('deepmind', 28), ('marathis', 28), ('kalpit', 28), ('bitconnect', 28), ('lstm', 28), ('eecs', 28), ('euron', 28), ('ucms', 28), ('÷', 28), ('mppsc', 28), ('psir', 28), ('acio', 28), ('rosenstein', 28), ('aktu', 28), ('somaiya', 28), ('iiits', 27), ('fyers', 27), ('wbcs', 27), ('davv', 27), ('aiats', 27), ('trumpcare', 27), ('venmo', 27), ('svnit', 27), ('alabamians', 27), ('tapmi', 27), ('hbtu', 26), ('narsee', 26), ('xxxtentacion', 26), ('owaisi', 26), ('airpods', 26), ('mmmut', 26), ('capf', 26), ('kellyanne', 26), ('iimc', 26), ('wannacry', 26), ('onedrive', 25), ('raghuram', 25), ('csab', 25), ('epfo', 25), ('despacito', 25), ('keam', 25), ('hkust', 25), ('kmno4', 25), ('enfps', 25), ('nlus', 25), ('vssut', 25), ('thaad', 24), ('mgtow', 24), ('nlsiu', 24), ('jorah', 24), ('irodov', 24), ('electroneum', 24), ('zamasu', 24), ('mohajirs', 24), ('são', 24), ('ftii', 24), ('grammarly', 24), ('cbcs', 24), ('spjimr', 24), ('gamora', 24), ('arrowverse', 24), ('codeforces', 24), ('sambhaji', 24), ('trumpers', 24), ('lnct', 24), ('ropar', 24), ('jallikattu', 23), ('g5s', 23), ('baelish', 23), ('eflu', 23), ('monjee', 23), ('genderfluid', 23), ('kovind', 23), ('telugus', 23), ('iiith', 23), ('simpliv', 23), ('pqwl', 23), ('hno3', 23), ('nimcet', 23), ('epfl', 23), ('internshala', 23), ('kingsman', 23), ('hbti', 22)]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "clean_oov = check_coverage(clean_vocab, embeddings_index)\n",
    "print(clean_oov[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'°c'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1efaa9305165>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membeddings_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'°c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: '°c'"
     ]
    }
   ],
   "source": [
    "embeddings_index['°c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"a ## b  ##    asdf \\t \\nasd\"\n",
    "b = a.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', '##', 'b', '##', 'asdf', 'asd']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
